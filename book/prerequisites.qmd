# Prerequisites {#sec-prerequisites}

## Knowledge

We assume basic familiarity with Python, ideally including its core scientific libraries such as NumPy, Pandas, Matplotlib, and Jupyter.

## Hardware

This is a hands-on course, so please bring your own **laptop** and **charger**.  
A **mouse** is strongly recommended, especially for tasks like image annotation.  
A dedicated **GPU is not required**, though it may speed up some computations.

## Software

You'll need both general tools for Python programming and specific software required for the course, as detailed below.

### General development tools {#sec-install-devtools}

::: {.callout-note}  
If you already have a working Anaconda or Miniconda installation and have used it to run Python scripts or Jupyter notebooks, you can likely skip the steps below.  
:::

To prepare your computer for Python development, we recommend following the [Software Carpentries installation instructions](https://carpentries.github.io/workshop-template/install_instructions), in particular:

- [Bash Shell](https://carpentries.github.io/workshop-template/install_instructions/#shell), to run terminal commands
- [Git](https://carpentries.github.io/workshop-template/install_instructions/#git), including a GitHub account
- [Python](https://carpentries.github.io/workshop-template/install_instructions/#python), via the [conda-forge installer](https://conda-forge.org/download/). Please make sure you install a **Python version >= 3.12** (e.g. 3.12 is fine, 3.10 is not).

You'll also need a code editor (IDE) configured for Python.  
If you already have one you're comfortable with, feel free to use it. Otherwise, we recommend:

- [Visual Studio Code](https://code.visualstudio.com/) with the [Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)
- [JupyterLab](https://jupyter.org/install)

### For the SLEAP tutorial {#sec-install-sleap}

Please install [SLEAP](https://sleap.ai/) following the [official installation instructions](https://sleap.ai/installation.html).

::: {.callout-note}  
For this workshop, use **SLEAP version 1.3.4**. Be sure to replace the default version number (e.g. `1.4.1`) in the instructions with `1.3.4`.  
:::

This should create a `conda` environment named `sleap` with the necessary dependencies. You can verify the installation by running:

```bash
conda activate sleap
sleap-label
```

This should launch the SLEAP graphical user interface (GUI).

### For the interactive notebooks {#sec-install-movement}

You will also need a separate `conda` environment with everything required for the interactive exercises, including the [movement](https://movement.neuroinformatics.dev/) and [jupyter](https://jupyter.org/) packages.

We recommend cloning this workshop's repository and creating the environment using the provided `environment.yaml` file:

```bash
git clone https://github.com/neuroinformatics-unit/animals-in-motion.git
cd animals-in-motion
conda env create -n animals-in-motion-env -f environment.yaml
```

To test your setup, run:

```bash
conda activate animals-in-motion-env
movement launch
```

This should open the [movement GUI](https://movement.neuroinformatics.dev/user_guide/gui.html), i.e. the [napari](https://napari.org/) image viewer with the `movement` plugin docked on the right.

::: {.callout-note}  
There are other ways to [install the movement package](https://movement.neuroinformatics.dev/user_guide/installation.html).  
However, for this workshop, we recommend using the `environment.yaml` file to ensure that all necessary dependencies, including those beyond `movement`, are included.  
:::

## Data {#sec-data}

Bringing your own data is encouraged but not required. This could include video recordings of animal behaviour and/or motion tracking data you've previously generated.

We also provide some example datasets for you to use during the workshop.
Please download these from [Dropbox](https://www.dropbox.com/scl/fo/81ug5hoy9msc7v7bteqa0/AH32RLdbZqWZJstIeR4YHZY?rlkey=blgagtaizw8aac5areja6h7q1&st=xni448zl&dl=0) before the workshop starts (they are a few GB in size).

The Dropbox folder is structured as follows:

```
Animals-in-Motion_2025-08/
├── CalMS21/
│   ├── better_model/
│   │   ├── 250806_174722.centroid.n=679/
│   │   ├── 250807_162146.multi_class_topdown.n=679/
│   │   └── predictions/
│   ├── mouse044_task1_annotator1.mp4
│   ├── mouse044_task1_annotator1.slp
│   └── readme.md
└── Smart-Kages.zip
```

- **CalMS21**: Contains an example video from the [Caltech Mouse Social Interactions (CalMS21) Dataset](https://sites.google.com/view/computational-behavior/our-datasets/calms21-dataset) [@sun_caltech_2021], SLEAP labels and trained models.
  - **better_model**: SLEAP multi-animal top-down ID model trained on 679 labelled frames.
    - **250806_174722.centroid.n=679**: Centroid model.
    - **250807_162146.multi_class_topdown.n=679**: Top-down ID model.
    - **predictions**: Model predictions on the full video.
  - **mouse044_task1_annotator1.mp4**: Video file used in [@sec-sleap].
  - **mouse044_task1_annotator1.slp**: Fully annotated SLEAP labels file (converted from MARS [@mars2021] pose estimates provided in the CalMS21 dataset).
  - **readme.md**: Information about the dataset (from the CalMS21 dataset).
- **Smart-Kages.zip**: Compressed dataset used in [@sec-movement-mouse].
